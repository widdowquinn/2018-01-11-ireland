{
    "collab_server" : "",
    "contents" : "---\ntitle: \"`pyani` Progress and Roadmap\"\nauthor: \"Leighton Pritchard\"\ndate: \"23/10/2017\"\noutput:\n  ioslides_presentation:\n    css: ./includes/custom.css\n    font-family: 'Helvetica'\n    widescreen: True\n    mathjax: local\n    self_contained: false\nruntime: shiny\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = FALSE)\n\nlibrary(dplyr)\nlibrary(ggnetwork)\nlibrary(ggplot2)\nlibrary(googleVis)\nop = options(gvis.plot.tag='chart')\nlibrary(igraph)\nlibrary(intergraph)\nlibrary(knitr)\nlibrary(stringr)\nlibrary(tidyr)\n\n# SCALING DATA\n#============================\n# A dataframe to illustrate how the number of required alignments\n# scales with input sequences for ANI\nscaledf = data.frame(seq.count=c(2, 5, 10, 50, 100, 500, 1000, 5000, 10000))\nscaledf$all.vs.all = scaledf$seq.count^2 - scaledf$seq.count\nscaledf$anim = scaledf$all.vs.all/2\n\n# Show effect of increasing number of cores, in days to run\ncores = scaledf[, c(\"seq.count\", \"anim\")]\ncores$cores.001 = cores$anim\ncores$cores.004 = cores$anim/4\ncores$cores.016 = cores$anim/16\ncores$cores.128 = cores$anim/128\ncores = cores %>% select(-anim) %>% gather(cores, days, -seq.count)\ncores$days = cores$days/(60*60*24)\n\n# SRE Taxonomy Sankey Plots\n#===========================\n\n# Reclassified isolates\ngenus = read.table(\"data/dickeya/genus_sankey.csv\", sep=\",\", header=TRUE)\nspecies = read.table(\"data/dickeya/species_sankey.csv\", sep=\",\", header=TRUE)\ngcs = read.table(\"data/dickeya/genus_class_species.csv\", sep=\",\", header=TRUE)\n\n# Relationships between historical taxonomic classifications\nsretaxdata = data.frame(origin=c(rep('E. carotovora', 3),\n                                 'E. chrysanthemi',\n                                 rep('P. carotovorum', 2),\n                                 'P. atrosepticum',\n                                 'P. wasabiae',\n                                 rep('P. chrysanthemi', 6)),\n                        renamed=c('P. carotovorum',\n                                  'P. atrosepticum',\n                                  'P. wasabiae',\n                                  'P. chrysanthemi',\n                                  'P. c. subsp. carotovorum (Pcc)',\n                                  'P. c. subsp. brasiliense (Pcb)',\n                                  'P. atrosepticum (Pba)',\n                                  'P. wasabiae (Pwa)',\n                                  'D. dianthicola',\n                                  'D. dadantii',\n                                  'D. zeae',\n                                  'D. chrysanthemi',\n                                  'D. dieffenbachiae',\n                                  'D. paradisiaca'),\n                        weights=c(6, 6, 6, 6,\n                                  rep(3, 2),\n                                  rep(6, 2),\n                                  rep(1, 6)))\n```\n\n<!--\nSECTION 1: Context\n--!>\n\n# 1. Context\n\n## Background\n\n<!-- This is needed to get the Hutton background throughout --!>\n<img src=\"images/hutton_background.png\" width=\"0px\" height=\"0px\" />\n\n- RD2.1.4: \"[a] resource for rapid molecular fingerprinting of Dickeya and Pectobacterium\"\n\n<div class=\"highlight\">\n- `pyani` evolved from diagnostics work on *Pectobacterium*/*Dickeya*\n- computational tool for rapid calculation and analysis of average nucleotide identity (ANI)\n    - First release August 2015; Current release: v0.2.5 (Sep 2017)\n</div>\n\n- Public webpage: [http://widdowquinn.github.io/pyani/](http://widdowquinn.github.io/pyani/)\n- Available as `Docker` container:\n    - `docker run -v ${PWD}:/host_dir leightonpritchard/average_nucleotide_identity`\n   \n   \n## Average Nucleotide Identity (ANIm)\n\n<div class=\"highlight\">\n**Whole-genome sequence replacement for DDH**\n</div>\n\n<div class=\"col2\">\n- align genomes\n- calculate mean %identity of all homologous regions\n- **\"70% identity\" (DDH) ≈ 95% identity (ANIm)**\n\n<p>\n<img src=\"images/ddh_anim.png\" width=\"100%\" />\n</p>\n</div>\n\n<div class=\"attention\">\n- insensitive to dataset composition (unlike clustering)\n- **approximate limiting case of MLST/MLSA/multigene comparisons**\n</div>\n\n<div class=\"references\">\n- [Goris *et al.* (2007) *Int. J. Syst. Microbiol.* doi:10.1099/ijs.0.64483-0](https://dx.doi.org/10.1099/ijs.0.64483-0) - ANI method\n- [Richter and Rossello-Mora (2009) Proc. Natl. Acad. Sci. USA doi:10.1073/pnas.0906412106](https://dx.doi.org/10.1073/pnas.0906412106) - ANIm method, JSpecies tool\n</div>\n\n## `pyani`\n\n<div class=\"highlight\">\n**`python` package and scripts for ANI**\n</div>\n\n<div class=\"col2\">\n- available on `PyPI` and `Docker`\n- ANIm, ANIb etc.\n- calculates, visualises results\n- parallelises under SGE/OGE\n<center>\n<img src=\"images/anim_pectobacterium.png\" width=\"70%\" />\n</center>\n\n<p>\n<img src=\"images/pyani_github_page.png\" width=\"100%\" />\n</p>\n</div>\n\n<div class=\"references\">\n- [Pritchard *et al.* (2015) *Anal. Methods* doi:10.1039/C5AY02550H](https://dx.doi.org/10.1039/C5AY02550H) - `pyani` used on SRE\n</div>\n\n\n## `pyani` in the wild\n\n<div class=\"highlight\">\n**Downloads**\n\n- Since 2015: 22117\n- 2017: 12808\n- October 2017: 2164\n</div>\n\n- Used at `LINBase`: [Life Identification Numbers](http://128.173.74.68/CodeIgniter/index.php/login), Virginia Tech.\n\n<div class=\"attention\">\n**Citations**\n\nHard to track - editors/authors don't often cite DOIs - at least 12 papers used it, including:\n\n- Burstein *et al.* (2016) \"New CRISPR–Cas systems from uncultivated microbes\" *Nature* [doi:10.1038/nature21059](https://dx.doi.org/10.1038/nature21059)\n</div>\n\n\n# 2. What it does well\n\n## Scaling\n\n- ANI is based on pairwise genome alignments\n- Sequence alignment is computationally expensive\n- The number of alignments scales with the square of sequences to be aligned: $O(n^2)$\n\n<div class=\"col2\">\n```{r}\nscaledf\n```\n\n<p><center>\n```{r fig.width=4, fig.height=4}\np1 = ggplot(scaledf, aes(x=seq.count, y=anim))\np1 + geom_point() + scale_y_log10() + scale_x_log10()\n```\n</center></p>\n</div>\n\n\n## Parallelisation\n\n<div class=\"highlight\">\nWe can't avoid the alignment, *but* we can use all available processors\n</div>\n\n- desktop/laptop: `multiprocessing` - one alignment per core\n- cluster: `SGE/OGE` - one alignment per core (not in `JSpecies`)\n\n<center>\n```{r, fig.height=4}\np1 = ggplot(cores, aes(x=seq.count, y=days, color=cores))\np1 + geom_point() + stat_smooth(aes(x=seq.count, y=days), method=\"loess\")\n```\n</center>\n\n\n## Visualisation\n\n<div class=\"highlight\">\n`pyani` produces tables of output, but also heatmaps/dendrograms\n</div>\n\n- clear visualisation of \"species\" boundaries\n\n<div class=\"col2\">\n<img src=\"images/anim_dickeya.png\" width=\"100%\" />\n\n<p>\n<img src=\"images/anim_rickettsia.pdf\" width=\"100%\" />\n</p>\n</div>\n\n\n## Coverage measures\n\n<div class=\"attention\">\nANI (and `JSpecies`) reports only identity of aligned regions.\n\nWe want to know how much of each genome aligns.\n</div>\n\n<div class=\"col2\">\n<img src=\"images/coverage_dickeya.png\" width=\"100%\" />\n\n<p>\n<img src=\"images/coverage_rickettsia.pdf\" width=\"100%\" />\n</p>\n</div>\n\n\n## Meaningful interpretation\n\n<div class=\"highlight\">\nVisualising coverage and identity together is more powerful:\n\n\"species\" and \"genus\" identification\n</div>\n\n<div class=\"col2\">\n<img src=\"images/anim_rickettsia.pdf\" width=\"100%\" />\n\n<p>\n<img src=\"images/coverage_rickettsia.pdf\" width=\"100%\" />\n</p>\n</div>\n\n\n# 3. How to improve\n\n## Installation and use\n\n<div class=\"attention\">\n`pyani` has multiple dependencies\n\n- `Python` and several packages\n- `MUMmer`/`BLAST+`\n\nNot all run on Windows, and program versions matter.\n</div>\n\n<div class=\"highlight\">\nThe `Docker` container system:\n\n- allows all dependencies to be packaged together\n- can be run on Windows/OSX/Linux\n</div>\n\n- install Docker: [https://www.docker.com/docker-windows](https://www.docker.com/docker-windows)\n- run `pyani`: `docker run -v ${PWD}:/host_dir leightonpritchard/average_nucleotide_identity`\n\n\n## User Interface (UI)\n\nCurrently two scripts:\n\n- `average_nucleotide_identity`\n- `genbank_get_genomes_by_taxon`\n\n<div class=\"attention\">\n*Many* options to be specified makes for long command-lines\n</div>\n\n```\n$ average_nucleotide_identity.py -o OUTDIR -i INDIR \\\n  -m ANIm -v -f -l LOGFILE \\\n  -g --gformat pdf,png,svg --gmethod seaborn \\\n  --labels LABELS --classes CLASSES \\\n  --scheduler SGE --jobprefix ANIm_Rickettsia\n```\n\n<div class=\"attention\">\n- easy to make mistakes\n- all possible actions run in a single command, but decomposition is possible\n</div>\n\n## User Interface (UI)\n\n<div class=\"highlight\">\nBreak analysis into steps, *via* subcommands\n</div>\n\n```\npyani.py download SEQDIR -v \\\n     --email my.email@my.domain -t 203804 \\\n     -l LOGFILE\npyani.py createdb -v -l LOGFILE\npyani.py anim SEQDIR ANIDIR -v -l LOGFILE --name NAME \\\n     --labels LABELS --classes CLASSES\npyani.py report -v --runs OUTDIR --formats html,excel,stdout \\\n     --run_results 1,3\npyani.py plot OUTDIR 1,3 -v --formats png,pdf\n```\n\n1. Download genomes\n2. Create database\n3. Run analysis (results $\\rightarrow$ database)\n4. Report results\n5. Visualise results\n\n\n## Database backend\n\n<div class=\"attention\">\nAdding/removing even a single genome to the analysis would require the complete analysis to be re-run\n</div>\n\n<div class=\"highlight\">\nStoring previous results in a database means we never have to rerun a pairwise comparison\n</div>\n\n<center>\n```{r, fig.height=4}\np1 = ggplot(cores, aes(x=seq.count, y=days, color=cores))\np1 + geom_point() + stat_smooth(aes(x=seq.count, y=days), method=\"loess\")\n```\n</center>\n\n\n## Database backend\n\n<div class=\"highlight\">\n[`SQLite3`](https://www.sqlite.org/): lightweight RDBMS\n</div>\n\n- persistent storage: run once, report/visualise many times\n- makes additive, incremental extension analyses possible\n- can be located/shared anywhere (created in current directory by default)\n    - can have a 'global' database, and an independent 'local' database\n- can be merged with other databases (combining precalculated results)\n\n<div class=\"highlight\">\nForces analyses to be transparent and reproducible\n</div>\n\n## Identifying unique analyses\n\n<div class=\"attention\">\nHow can we determine whether a pairwise comparison has been run before?\n</div>\n\n**Metadata**\n\n- same sequence\n- same analysis type (ANIm/ANIb/ANIblastall/TETRA)\n- same program (BLASTN/MUMmer) and version\n- same program options (`--maxmatch`, substitution matrix)\n\n<div class=\"highlight\">\nForces analyses to be transparent and reproducible\n</div>\n\n\n## Identifying the same sequences\n\n<div class=\"attention\">\nNot by global pairwise alignment - that's what we're trying to avoid!\n</div>\n\n<div class=\"highlight\">\n**Hash functions**\n\n- one-way 'trapdoor' functions: $f(\\textrm{input}) \\rightarrow \\textrm{much smaller output}$\n- output is fixed size\n- distinct inputs should give distinct outputs (no *collisions*)\n- small changes in input $\\rightarrow$ large changes in output\n</div>\n\n- Each unique genome is represented by its (ND5) *hash*\n\n**Common hashes**\n\n- MD5, SHA-256, CRC, etc.\n- often used to uniquely identify large documents/files\n\n<div class=\"references\">\n- [https://en.wikipedia.org/wiki/Hash_function](https://en.wikipedia.org/wiki/Hash_function) - hash functions at Wikipedia\n</div>\n\n## Identifying the same sequences\n\n<div class=\"highlight\">\n`pyani` avoids repeating analyses\n</div>\n\n- user provides a directory of genomes\n- `pyani` calculates/checks the hashes of all the genomes against the database: has it seen them?\n- `pyani` identifies which comparisons need to be made\n    - notes program versions and arguments\n    - checks if combination of genomes/program/arguments already run\n    - if comparison already run, it is not rerun, and the result is used again\n    \n<div class=\"highlight\">\nThe analysis is rerun and stored in the database again if:\n\n- the sequence has changed\n- the program (e.g. `MUMmer`) version has changed\n- the selection of alignment parameters has changed\n</div>\n\n\n## Automated classification\n\n**ANI Results Define Graphs**\n\n<div class=\"highlight\">\n**ANIm of all sequenced SRE genomes.** Edges > 50% coverage\n</div>\n\n- three main groups (genera)\n\n<center>\n<img src=\"images/sre_anim.png\" width=\"40%\" />\n<img src=\"images/sre_anim_graph.png\" width=\"40%\" />\n</center>\n\n## Automated classification\n\n<div class=\"highlight\">\n*cliques* - *k*-complete graphs - are 'natural' clusterings\n</div>\n\n- clique membership varies with ANI %identity\n- clique membership (at given %ID) is permanent and scales\n\n<div class=\"attention\">\nat some %identity values, all graph components are cliques, and all genomes belong to a single clique (no *confusion*)\n</div>\n\n<center>\n<img src=\"images/thresholds.png\" width=\"45%\" />\n<img src=\"images/threshold_zeros_kde.png\" width=\"45%\" />\n</center>\n\n\n## Network Deconstruction\n\n```{r network_deconstruct}\nsre_graph = read_graph('data/dickeya/sre_anim_graph.gml', format='gml')\n\nshinyApp(\n  ui = fluidPage(\n    fluidRow(\n      column(3,\n        sliderInput(\"identity\", label = \"Identity threshold:\",\n                    min = 0.85, max = 0.999, value = 0.85, step = 0.001)\n      ),\n      column(2,\n        radioButtons(\"legend\", \"legend\",\n                     choices=c(\"clique\", \"genus\", \"species\"))\n      ),\n      column(7,\n        textOutput(\"Status\"),\n        textOutput(\"Hover\")\n      )\n    ),\n    fluidRow(\n      column(12,\n        plotOutput(\"Network\", width=\"100%\",\n                   hover=hoverOpts(id=\"plot_hover\"))\n      )\n    )\n  ),\n  server = function(input, output) {\n    not_species <- reactive({\n      not_species = sre_graph %>% \n                      delete_edges(E(sre_graph)[identity<input$identity])\n      clist = max_cliques(not_species)\n      for (cnum in seq_along(clist)) {\n        not_species = set_vertex_attr(not_species, 'clique', clist[[cnum]],\n                                      cnum)\n                                     }\n      #fortify(not_species)\n      list(fortify(not_species),\n           count_max_cliques(not_species),\n           count_components(not_species))\n      })\n      \n    output$Network <- renderPlot({\n      data = not_species()[[1]]\n    \n      if (input$legend == 'clique') {\n        p = ggplot(data,\n                   aes(x=x, y=y,\n                       xend=xend, yend=yend,\n                       color=as.factor(clique)))\n      } else {\n        p = ggplot(data,\n                   aes_string(x=\"x\", y=\"y\",\n                              xend=\"xend\", yend=\"yend\",\n                              color=input$legend))\n      }\n      p = p + geom_edges(color = \"grey50\", alpha=0.3)\n      p = p + geom_nodes(alpha=0.4, size=3)\n      p = p + scale_color_discrete(name=input$legend)\n      p + theme_blank() + geom_nodes()\n     })\n     \n    output$Status <- renderText({\n      data = not_species()\n      \n      paste(\"Cliques:\", data[[2]], \"-\",\n            \"Components:\", data[[3]])\n    })\n    \n    output$Hover <- renderText({\n      data = not_species()[[1]]\n      data$x = as.vector(data$x)\n      data$xend = as.vector(data$xend)\n      data$y = as.vector(data$y)\n      data$yend = as.vector(data$yend)\n      data = data %>%\n               filter(is.na(coverage))\n      \n      if (!is.null(input$plot_hover)) {\n        hover = input$plot_hover\n        dist = sqrt((hover$x - data$x)^2 + (hover$y - data$y)^2)\n        cat(\"Organism: \")\n        if (min(dist) < 0.01) {\n          paste(\"Organism:\", data$species[which.min(dist)])\n        }\n      }\n    })\n  }\n)\n```\n\n\n## Reclassification: *Pectobacterium*\n\n```{r reclassify_pectobacterium}\nshinyApp(\n  ui = fluidPage(\n         fluidRow(column=12,\n          htmlOutput(\"Sankey\")\n         )\n       ),\n  server = function(input, output) {\n    output$Sankey = renderGvis({\n      gvisSankey(\n        gcs %>% \n          filter(str_detect(from, \"Pectobacterium\") | \n                 str_detect(to, \"Pectobacterium\")),\n        from='origin', to='renamed',\n        weight='weights',\n        options=list(height=500, width=900,\n                     sankey=\"{iterations: 1024,\n                     link: { color: {fillOpacity: 0.7},\n                             colorMode: 'gradient'},\n                             node: { label: {fontSize: 10,\n                                             italic: true},\n                                     colors: [ '#8dd3c7', '#ffffb3', '#bebada',\n                                               '#fb8072', '#80b1d3', '#fdb462',\n                                               '#b3de69', '#fccde5', '#d9d9d9',\n                                               '#bc80bd', '#ccebc5', '#ffed6f' ],\n                                     width: 5} \n                            }\"\n                    )\n                )\n    })\n  }\n)\n```\n<div class=\"references\">\n- [Faure *et al.* (2016) *Int. J. Syst. Microbiol* doi:10.1099/ijsem.0.001524](https://dx.doi.org/10.1099/ijsem.0.001524) - Reclassification of *P. wasabiae*\n</div>\n\n\n## Automated classification\n\n<div class=\"highlight\">\nImplement as a new `classify` subcommand to act on database contents.\n</div>\n\n```\n$ pyani.py classify OUTDIR RUN_ID \\\n    --cov_min COV_MIN --id_min ID_MIN \\\n    -l LOGFILE -v\nINFO: Returned graph has 6 nodes:\n\tC. Blochmannia pennsylvanicus BPEN_1\n\tC. Blochmannia floridanus_2\n\tC. Blochmannia vafer BVAF_3\n\tC. Blochmannia chromaiodes 640_4\n\tB. endosymbiont of Polyrhachis (Hedomyrma) turneri 675_5\n\tB. endosymbiont of Camponotus (Colobopsis) obliquus 757_6\n[...]\nINFO: Identifying 'natural breaks' with no clique-confusion:\n\t0.8288776504430938\tCliquesinfo(n_cliques=1, n_cliquenodes=6, confused=0)\n\t0.8579710144927536\tCliquesinfo(n_cliques=3, n_cliquenodes=6, confused=0)\n\t0.8661260963097799\tCliquesinfo(n_cliques=4, n_cliquenodes=6, confused=0)\n\t0.9802488223947734\tCliquesinfo(n_cliques=5, n_cliquenodes=6, confused=0)\nINFO: Completed. Time taken: 0.044s\n```\n\n\n## User-friendly output\n\n<div class=\"highlight\">\nPeople like clickable images/browser-based interfaces (`FastQC`, `QUAST`, etc.)\n</div>\n\n**Generating `.html`/JavaScript output**\n\n- views onto database contents and outputs\n    - all genomes in database\n    - all comparisons in database\n    - all results for a run\n    - ANIm matrix outputs\n    \n**Generating interactive plots with `plot.ly`**\n\n- interactive Sankey plots of classification\n- interactive plots of clique composition\n    \n\n",
    "created" : 1511803175266.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "146693638",
    "id" : "BDA53C67",
    "lastKnownWriteTime" : 1509640833,
    "last_content_update" : 1509640833,
    "path" : "~/Library/Mobile Documents/com~apple~CloudDocs/JHI_work/Presentations/presentation-2017-10-23_JHI/2017-10-23_JHI_Bacteriology.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}